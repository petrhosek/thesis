\chapter{Multi-version Execution}
\label{chap:multi-version}

An indisputable and widely accepted fact is that all software contains bugs.
These bugs cause software failures which can lead to anything from minor
discomfort and loss of service to major disasters including loss of lives.
Software reliability is the probability of failure-free operation for specified
period of time in a specified environment.

There are two basic approaches to increase software reliability. One is fault
avoidance, using formal specification and verification methods, and a rigorous
software development process. Another approach is fault tolerance, through
replication, redundancy and diversity. Two popular software fault tolerance
methods that use diversity are $N$-version programming~\cite{avizienis:nvp} and
recovery block~\cite{randell:rb}.

%$N$-version programming (NVP) has been first introduced in 1970's as a way to
%increase reliability of software by having independent teams to design and
%implement the same functionality multiple times from the same specification as
%different program versions. 

The idea behind $N$-version programming (NVP) is to have independent teams to
design and implement the same functionality multiple times from the same
specification as different program versions. These versions are then run in
parallel using an $N$-version execution environment (NVX) and their results are
voted on and the majority of the outputs is selected.

$N$-version programming depends on the assumption that software errors in
different versions are independent. Otherwise, these versions are not effective
at detecting errors as the different versions are likely to contain the same
bugs. The experiment done by Knight and Leveson~\cite{knight86,knight90} shown
that the assumption of independence does not hold and independently developed
versions had the same or similar software faults 50\% of the time in more than
one version since programmers tended to commit certain classes of mistakes
dependently.

Despite the criticism, $N$-version programming is still widely accepted as an
effective technique for improving reliability. The problem is that even small
probability of correlated bugs in different version significantly reduces the
potential reliability improvement, which makes the $N$-version programming less
cost-effective compared to other fault-tolerance due to a need for developing
$N$ different version. Lui Sha~\cite{lui01} compared different fault tolerance
approaches and suggested that, assuming finite software development cycle, it
is better to invest resources into a single reliable implementation rather than
three different implementations which will be run in parallel.

The issue of cost related to development of multiple independent versions has
been partially addressed by the multi-variant program execution, which can be seen
as an evolution of $N$-version programming. Rather than developing different versions
of the same application manually, these are generated from a single version
using different techniques such as special source code
annotations~\cite{onlinevalidation,trachsel10}, code transformations based on
the modification of the abstract syntax tree~\cite{schulte14,sosie:issta14},
custom compilers producing different binary layout for different
variants~\cite{orchestra09,unibus:nspw10}. %, or even specialized runtime
%environments which customize different aspects of application runtime
%state~\cite{diehard06,tightlip}.

Rather than executing $N$ different versions of the same program, we could also
run different programs where one program acts as a specification and other
implementations are checked against the specification at runtime.  This is the
basic idea behind runtime monitoring and checking~\cite{kim:mac,java-mac01}. In
runtime monitoring and checking, one program is the implementation while
another is the specification. The implementation is checked against the
specification at runtime, which is easier than proving the equivalence
statically (or formally).  Furthemore, the specification can be less efficient
and thus simple. The example shown by Lui Sha in~\cite{lui01} uses Bubblesort
as a runtime specification for Quicksort.

%However, Hatton~\cite{hatton97} argued that even dependent $N$-version
%programming provides significant reliability improvement and it is therefore
%more cost-effective to develop $N$ average versions rather than one good
%version.

\section{Software updates}

% Recent years have seen a growing interest in using diversity as a way to
% increase the reliability and security of software systems.  One form of
% software diversity that has attracted significant interest from the research
% community is the idea of running multiple diversified versions of a program in
% parallel in order to survive bugs and detect security attacks.  In essence,
% diversity can offer probabilistic guarantees that at least one variant survives
% a bug, or that a security attack will be flagged by divergent behaviour across
% variants.

% On the reliability side, which forms the main focus of this thesis, these
% diversified versions are either automatically-generated variants, multiple
% versions of the same application, or different programs implementing the same
% interface.  For example, one may run in parallel multiple variants that employ
% complementary thread schedules to survive concurrency
% errors~\cite{compl-schedules11}, multiple versions of the same software to
% survive update bugs~\cite{mx}, or multiple web browsers to benefit from the
% fact that many errors do not affect all browser
% implementations~\cite{cocktail}.  In this thesis, we show that running multiple
% versions in parallel can be used in other reliability scenarios, such as
% running expensive error detectors (``sanitizers'') during deployment.

% On the security side, these diversified variants are constructed in such a way
% as to reduce the probability of an attack succeeding in all of
% them~\cite{cox2006,orchestra09,diehard06,tightlip,capizzi08,devries10,cocktail,trachsel10}.
% For example, one may generate versions with a different arrangement of memory
% blocks in the address space~\cite{diehard06}, or with stacks growing in
% opposite directions~\cite{orchestra09}, to prevent attacks whose success
% depends on the memory layout.

One particularly important class of bugs are bugs introduced by software
updates. These bugs often affect existing functionality, degrading the
reliability, and potentially also security, of the software. This leads to
frustration as users are no longer able to use the functionality they have been
able to use in the past; as a consequence, users often refuse applying updates
to their software and rely instead on outdated versions, which may contain bugs
and security vulnerabilities.

To address this problem, we propose a variant of $N$-version execution focused
on improving reliability and availability of updated software:
\emph{multi-version execution}.  While $N$-version execution and multi-version
execution techniques have many similarities, there are several key differences.
First and foremost, in $N$-version execution the different version are
developed by different teams while multi-version execution uses the consequent
revisions, which are product of natural software evolution. Second, the goal of
$N$-version execution is increasing the reliability of software by running
independently developed, functionally equivalent software variants, whereas
multi-version assumes that the variants are largely the same except for parts
affected by the software update.

While designed primarily in the context of software updates, the multi-version
execution technique can be applied in many different scenarios, including
$N$-version execution. Furthermore, as shown in this thesis, multi-version
execution runtimes can be used in other reliability scenarios, such as running
expensive error detectors (``sanitizers'') during deployment or implementation
of security honeypots.

% There are two key differences between our proposed approach and
% previous work in this space.  First, we do not rely on automatically
% generated variants, but instead propose to use existing software
% versions as a mechanism for improving software updates.  This also
% means that as opposed to previous solutions, the versions running in
% parallel are not semantically equivalent---this eliminates the
% challenge of generating diversified variants and creates opportunities
% in terms of recovery from failures, but also introduces additional
% challenges in terms of synchronising the execution of the different
% versions.  Second, while previous work has focused on detecting
% divergences, our key concern is to \textit{survive} them,
% in order to increase the reliability, availability, and security 
% of the overall application.

% Running different versions of an application in parallel has been used
% to test and validate software patches.  Tachyon~\cite{tachyon12} is an
% online patch testing system in which the old and the new version of an
% application are run concurrently; 
% when a divergence is detected, the options are to either halt the
% program, or to create a manual rewrite rule specifying how to handle
% the divergence.  Delta execution~\cite{onlinevalidation} similarly
% uses two different versions of a single application, splitting the
% execution at points where the two versions differ, and comparing their
% results to test the patch for errors and validate its
% functionality.  
% By comparison, the focus of this proposal is on ``managing'' such
% divergences at runtime in order to keep the application running, and
% therefore runtime deployment and crash recovery play a central role in
% our approach.

% Research on surviving software failures has received a lot of
% attention in the
% past~\cite{rx,compl-schedules11,fo,exec-trans06,vigilante,clearview,microreboots},
% and our proposed approach can benefit from the techniques developed in
% this context.  Compared to this prior work, the main novelty lies in
% combining multiple software versions to survive failures.

\input{multi-version/scenarios}

\section{Parallel software execution}

% All the scenarios presented above describe software updates which, while trying
% to fix existing bugs or refactor the code, also introduced new bugs that caused
% the code to crash under certain conditions. Improving the reliability of such
% updates is the main goal of our proposed approach: running both the old and the
% new version in parallel after an update can enable applications to survive more
% errors, without giving up the new features introduced by the update.

% The bottom line for all the presented scenarios is that for significant amount
% of time, \ie about one year in case of \lighttpd and six months in case of
% \redis, users affected by buggy patches essentially had to decide between%
% \begin{inparaenum}[(1)]
% \item incorporating other security and bug fixes added to the code, but being
%   vulnerable to these crash bug, and
% \item giving up on these security and bug fixes and using an old version of
%   \lighttpd or \redis, which are not vulnerable to these newly introduced bugs.
% \end{inparaenum}
% Note that this is particularly true for the period between the time when the
% bug was introduced and the time it was diagnosed (\ie eleven months in case of
% \lighttpd, six months in case of \redis), since during this period most users
% would not know how to change the server's configuration to avoid the crash.

All the scenarios presented above describe software updates which, while trying
to fix existing bugs or refactor the code, also introduced new bugs that caused
the code to crash under certain conditions. The bottom line for all these
scenarios is that for significant amount of time, \ie about one year in case of
\lighttpd and six months in case of \redis, users affected by buggy patches
essentially had to decide between%
\begin{inparaenum}[(1)]
\item incorporating other security and bug fixes added to the code, but being
  vulnerable to these crash bug, and
\item giving up on these security and bug fixes and using an old version of
  \lighttpd or \redis, which are not vulnerable to these newly introduced bugs.
\end{inparaenum}
Note that this is particularly true for the period between the time when the
bug was introduced and the time it was diagnosed (\ie eleven months in case of
\lighttpd, six months in case of \redis), since during this period most users
would not know how to change the server's configuration to avoid the crash.

Our approach aims to provide users with a third choice; when a new version
arrives, instead of replacing the old version, we will run both. The goal
of our approach is to run multiple versions of an application in parallel, and
synchronize their executions so that%
\begin{inparaenum}[(1)]
\item users are given the illusion that they interact with a single version of
  the application,
\item the multi-version application is at least as reliable and secure as any
  of the individual versions in isolation, and
\item the synchronization mechanism incurs a reasonable performance overhead.
\end{inparaenum}

As shown in Figure~\ref{fig:mx-platform}, our solution requires a form of
virtualization framework that would coordinate the execution of multiple
application versions, and mediate their interaction with the external
environment. Various such frameworks have been designed in the past in the
context of running multiple automatically generated variants of a given
application in parallel~\cite{diehard06,cox2006,orchestra09}, and many of the
techniques proposed in prior work can be reused in our context.  To be
practical, this coordination mechanism has to incur a reasonable overhead on
top of native execution and ensure that the overall system is able to scale up
and down the number of software versions run in parallel in order to balance
conflicting requirements such as performance, reliability, security and energy
consumption.

\begin{figure}[t]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{multi-version/figures/platform}
    \caption{A platform running conventional and multi-version
      applications side by side.}
    \label{fig:mx-platform}
  \end{center}
\end{figure}

One particular challenge for our approach is to detect any divergences between
different software versions, resolve them in such a way as to increase the
overall reliability of the application, and finally synchronize again the
different versions after their executions reconverge to the same behavior.  Of
course, we also need to handle the case in which the executions of different
versions fail to reconverge to the same behavior after sufficient time.

Selecting the ``correct'' behavior of an application when different versions
disagree is of course not possible in the general case without having access to
a high-level specification.  However, one could%
\begin{inparaenum}[(1)]
\item focus on universal
correctness properties, such as the absence of crashes, and
\item use various
heuristics such as majority voting and favoring the latest application
versions.
\end{inparaenum}
Our approach is to resolve a divergence by always using the behavior of the
version that has not crashed, and favoring the behavior of the latest version
in all other cases. In this way, we ensure that the overall application has
strictly fewer crashes than any of the individual versions, while still using
the new security and bug fixes implemented in the latest version.

% Note that one key aspect on which our approach relies is
% \textit{having the different versions be alive at all times}.  This ensures
% that applications can survive crashes that occur at different points
% in different versions, but adds the extra challenge of restarting
% crashed versions.

%% Once divergences are detected, we need to decide what output should be
%% selected as the output of the multi-version system in order to improve
%% overall reliability.  Many different strategies can be used, but the
%% common goal is to ensure that the multi-version system will have
%% strictly fewer errors than any of the individual versions.

% Finally, our approach needs a deployment strategy to decide what versions are
% run in parallel when the number of available resources (\eg, idle CPU cores) is
% limited.  We envision several options---such as keeping the last $N$ released
% versions (where $N$ is the number of available resources), or keeping several
% very old stable versions---but the exact strategy should be decided on a
% case-by-case basis. % using existing empirical data.

\section{Challenges}

There are several different ways to implement an effective system call monitor,
each with its own set of trade-offs. The solutions targeting binaries are
significantly easier to use---they can be typically applied to off-the-shelf
binaries---but compared to solutions operating at source code level, they give
up some of the precision while typically require more engineering effort. The
most common ways for implementing monitors operating on binaries are dynamic
linking, \ptrace, kernel extensions and binary instrumentation, while solutions
targeting source code typically rely on source code instrumentation.

System calls are rarely performed directly by the application, which rather use
the wrapper functions provided by the C library. By linking to a custom
library, which provides a custom version of these functions, we could intercept
system calls performed by the application. This could be done either statically
at link time~\cite{plash}, or dynamically at runtime~\cite{shepherding:pldi14}
(\eg using \lstinline`LD_PRELOAD` or \lstinline`DYLD_INSERT_LIBRARIES`
variables). The major benefit of this approach is efficiency and relative ease
of implementation. However, the mechanism could be easily bypassed (\eg by
invoking system calls directly); also the C library ABI is has significantly
larger surface compared to the system call interface, requiring more
engineering effort.

\ptrace is an interface provided by most UNIX-like operating systems, including
Linux, providing means by which a process might observe and control another
process. The primary use of \ptrace interface is for debugging, but the
relative ease of use makes \ptrace a popular choice for implementing system
system call monitors~\cite{wily-hacker,orchestra09,tachyon12}. \ptrace-based
solutions require relatively low engineering effort, which makes them
especially suitable for rapid prototyping~\cite{spillane07}, they are easy to
deploy and fairly flexible. On the other hand, the use of \ptrace has numerous
drawbacks: a significant performance overhead due to large number of context
switches, problematic support for multi-threaded applications, and the lack of
filtering mechanism allowing interception only of system calls of interest.
\ptrace-based solution are also more difficult to debug as the use of \ptrace
disallows the use of \ptrace-based debuggers such as \gdb.

% The performance overhead could be partially improved by the use of
% more efficient mechanism for copying memory from/to the monitored process, such
% as shared memory as in case of Orchestra~\cite{orchestra09}, or cross memory
% attach as in case of \mx (\S\ref{sec:mxm}). The lack of filtering mechanism
% could be addressed by combining \ptrace with \textsf{seccomp/bpf} mechanism as
% shown by \textsc{Mbox}~\cite{mbox}.

An alternative to \ptrace is to implement the system call monitor
entirely~\cite{provos2002,cox2006} or partially in kernel space~\cite{ostia}.
While this approach has numerous advantages compared to other approaches, such
as minimal performance overhead and direct access to the application's
execution context and address space, there are several drawbacks.  First, this
approach requires kernel patches and/or new new kernel modules which
complicates the development, limits portability across different operating
systems or even different kernel versions, and hinders maintainability. Second,
the monitor must be run in privileged mode, which means that bugs in the
implementation may compromise the system stability. Furthermore, it also makes
it difficult for regular users to deploy and use such monitors.

Binary rewriting technique allow transforming the executable (either statically
or dynamically) altering its functionality; as such, it can be used to
implement system call monitor by rewriting all system call instructions into a
control flow transfer instructions (\eg a
\lstinline[language={[x64]Assembler}]`jmp` instruction). Existing monitors were
built either on top of existing binary rewriting
systems~\cite{onlinevalidation}, or using a purpose built binary translation
mechanism~\cite{vx32}. The advantage of binary rewriting-based monitors is
relatively low performance overhead, especially in the case of purpose built
rewriting mechanism. The main disadvantage is the complexity of implementation
which requires significant development effort.

In this thesis, we present two different designs for building monitors suitable
for multi-version execution. The first one, called \varan described in
Chapter~\ref{chap:efficient-execution}, is aimed towards running large number
of versions side-by-side with low performance overhead, and uses selective
binary rewriting to achieve this goal. The second one, called \mx described in
Chapter~\ref{chap:safe-updates}, is focused on surviving crashes caused by bugs
introduced in software updates, with the prototype implementation built using
the \ptrace mechanism.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Our approach aims to provide users with a third choice; when a new version
% arrives, instead of replacing the old version, we run both versions in
% parallel. In our example, consider that we are using \mx to run a
% version of \lighttpd from March 2009.  When the buggy April 2010 version
% is released, \mx runs it in parallel with the old one.  As the two
% versions execute:

% \begin{itemize}
% \item As long as the two versions have the same external behaviour (\eg they
%   write the same values into the same files, or send the same data over the
%   network), they are run side-by-side and \mx ensures that they act as one to
%   the outside world;

% \item When one of the versions crashes (\eg the new version executes the buggy
%   patch), \mx will patch the crashing version at runtime using the behaviour of
%   the non-crashing version.  In this way, \mx can successfully survive crash
%   bugs in both the old and the new version, increasing the reliability and
%   availability of the overall application;

% \item When a non-crashing divergence is detected, \mx will discard one of the
%   versions (by default the old one, but other heuristics can be used).  The
%   other version can be later restarted at a convenient synchronisation point
%   (\eg at the beginning of the dispatch loop of a network server).
% \end{itemize}

% To enable these scenarios, a monitor process coordinates the parallel execution
% of these variants\footnote{The terms \textit{version} and \textit{variant} are
% used interchangeably.} and synchronises their execution, making them appear as
% a single application to any outside entities.  While synchronisation can be
% performed at different levels, the most common approach is to do it at the
% level of system calls, for two main reasons: first, many existing
% diversification transformations, such as address-space layout
% randomisation~\cite{diehard06} and instruction-set
% randomisation~\cite{instr-set-rand03} do not change the sequence of system
% calls (the program's \textit{external behaviour}), and the ordering is often
% preserved even across different software versions.  Second, system
% calls are the main way in which the application communicates with the outside
% environment, and therefore
% %% the ultimate target of attackers.  Finally, as the main
% %% communication mechanism between applications and the environment,
% %% system calls
% must be virtualised in order to enable the multiple versions to act as
% one to the outside world.
