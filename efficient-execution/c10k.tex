\subsection{C10k servers}
\label{sec:c10k}

Existing NVX systems, including those based on \lstinline`ptrace`, can
already run CPU-bound applications efficiently with an overhead
typically less than \SI{20}{\percent}.  As a result, we focus our evaluation on
high-performance, heavily I/O-bound C10k servers\footnote{Numeronym used
  for servers capable of concurrently handling ten thousand connections.}
  which%
\begin{inparaenum}[(1)]
\item represent the worst-case scenario for a system call monitor; and
\item form the backbone of modern, highly-scalable web applications,
  for which reliability is critical.
\end{inparaenum}

The \nservers server applications used in our evaluations are
summarized in Table~\ref{tbl:apps} (the size is measured in lines of
code, as reported by the \emph{cloc} tool). For our performance experiments, we
ran the same version of each application multiple times with different number
of instances. 
%(in practice you would typically run different versions as shown in \S\ref{sec:applications}).  
Each experiment was performed six times, with
the first measurement used to warm up the caches and discarded.  The overhead
was calculated as a median of the remaining five measurements.

\begin{table}
\begin{center}
\caption{Server applications used in the evaluation.}
\begin{tabular}{lrl}
  \toprule
  \textsc{Application} & \textsc{Size} & \textsc{Threading} \\
  \midrule
  Beanstalkd & 6365 & single-threaded \\
  Lighttpd & 38,590 & single-threaded\\
  Lighttpd 2.0 & 47,873 & multi-threaded\\
  Memcached & 9779 &  multi-threaded\\
  Nginx & 101,852 & multi-process\\
  Redis & 34,625 & multi-threaded\\
  \bottomrule
\end{tabular}
\end{center}
\label{tbl:apps}
\end{table}

% \begin{figure}[!t]
%   \centering
%   \includegraphics[width=\columnwidth]{results/macro}
%   \caption{Performance overhead for the \beanstalkd, \lighttpd and \nginx servers for different number of followers.}
%   \label{fig:servers}
% \end{figure}

% \begin{figure*}[!t]
%  \centering
%  \includegraphics[width=0.6\textwidth]{results/c10k}
%  \caption{Performance overhead for the \beanstalkd, \lighttpd and \nginx servers for different number of followers.}
%  \label{fig:servers}
% \end{figure*}

% \begin{figure*}[!t]
%  \centering
%  \includegraphics[width=0.6\textwidth]{results/macro_redis}
%  \caption{Performance overhead for \redis operations for different number of followers.}
%  \label{fig:redis}
% \end{figure*}

\begin{figure}[!t]
 \centering
 \includegraphics[width=\textwidth]{efficient-execution/graphs/c10k}
 \caption{Performance overhead for the \beanstalkd, \lighttpd, \nginx
   and \redis servers for different number of followers.  The client
   and server are located on the same rack, simulating a worst-case scenario.}
 \label{fig:servers}
\end{figure}

We give a short overview of each benchmark and the way in which we
measure performance (namely throughput) in our experiments:

\paragraph{\beanstalkd}\footnote{\url{http://kr.github.io/beanstalkd/}}
is a simple and fast work queue, used by a number of websites to
distribute jobs among workers. We used revision \lstinline`157d88b` from the
official \git repository, the latest revision at the time of
writing.  To measure performance, we used
\lstinline`beanstalkd-benchmark`\footnote{\url{https://github.com/fangli/beanstalkd-benchmark}}
with \num{10} concurrent workers each performing \num{10000} push operations
using \SI{256}{\byte} of data per operation.

%\boldtext{\textit{Lighttpd}}\footnote{\url{http://www.lighttpd.net/}}
%is a lightweight web server optimized for high performance
%environments. The version used for the measurements was 1.4.36,
%the latest version in the 1.4.x series at the time of writing.
%We measured the performance of serving a \SI{4}{\kilo\byte} page using
%\lstinline`wrk`, which was run for \SI{10}{\second} with \num{10} clients.

\paragraph{\lighttpdtwo}\footnote{\url{https://github.com/lighttpd/lighttpd2}}
is a lightweight web server optimized for high performance environments,
reimplemented entirely from the scratch in the version 2.0.  We used the
revision \lstinline`93d04a3` from the official \git repository, the
latest revision at the time of writing. We measured the performance of serving
a \SI{4}{\kilo\byte} page using
\lstinline`wrk`,\footnote{\url{https://github.com/wg/wrk}}, which was run for
\SI{10}{\second} with \num{10} clients.

%% \lstinline`weighttpd`\footnote{\url{https://github.com/lighttpd/weighttp}},
%% which is the benchmarking tool developed by the authors of
%% \lighttpd. We set up \lstinline`weighttpd` to perform \num{100,000} requests,
%% using \num{10} concurrent clients running in \num{2} threads.
%The results can be seen in Figure~\ref{fig:macro_lighttpd}.

\paragraph{\memcached}\footnote{\url{http://memcached.org/}} 
is a high-performance, distributed memory object caching system, used by
many high-profile websites to alleviate database load. We used the
revision 1.4.17, latest at the time of writing. To measure the performance
overhead, we used the \emph{memslap} benchmark,\footnote{url{http://libmemcached.org/}}
part of the \emph{libMemcached} library. We used the default workload,
\ie initial load of \num{10000} key pairs and \num{10000} test executions.

%% To measure the performance overhead introduced by \varan when running
%% \memcached, we used \lstinline`memslap`, a load generation and benchmarking
%% tool for \memcached, which is a part of
%% \lstinline`libmemcached`.\footnote{\url{http://libmemcached.org/}}

\paragraph{\nginx}\footnote{\url{http://nginx.org/}}
is a highly popular reverse proxy server often used as an HTTP web
server, load balancer or cache. We used version 1.5.12, the
latest at the time of writing.  We measured
performance using the same workload as for \lighttpdtwo.

%% measured the performance of serving
%% a simple HTML webpage using
%% \lstinline`wrk`,\footnote{\url{https://github.com/wg/wrk}} which was run for
%% \SI{10}{\second} with \num{10} clients.

\paragraph{\redis}\footnote{\url{http://redis.io/}}
is a high-performance in-memory, key-value data store, used by many
well-known services. % such as Twitter, GitHub and StackOverflow.
% Pinterest, Snapchat, Craigslist, Digg, Flickr 
We used version 2.9.11 in our experiments.  To measure
performance, we used
\emph{redis-benchmark},\footnote{\url{http://redis.io/topics/benchmarks}}
distributed as part of Redis. The benchmark issues different types
of commands supported by Redis and measures both the throughput and
the latency for each type. We used the default workload, \ie 50
clients issuing \num{10000} requests and calculated and average overhead
across all commands. 

Figure~\ref{fig:servers} shows the results for all servers. All
performance numbers are obtained using the client-side tools presented
above.  Since the client machine is located on the same rack as the
server, these numbers represent a worst-case scenario, as the network
latency would hide some of the overhead for a more distant client
machine.

%Figures~\ref{fig:servers} and \ref{fig:redis} show the results for all
%servers.  The results for \redis are shown separately, because \redis
%has 16 different command types.  All performance numbers are obtained
%using the client-side tools presented above.  Since the client machine
%is located on the same rack as the server, these numbers represent a
%worst-case scenario, as the network latency would hide some of the
%overhead for a more distant client machine.

For each benchmark, we show one bar, normalized relative to native
execution, showing the performance of \varan using a given number of
followers.  We stop at six followers, because our machine has eight
threads, and we also need one thread for the leader and one for the
coordinator.  
%For space reasons, for \redis we show results for only 0, 3 and 6 followers.

The set of bars for 0 followers measure the interception overhead
of \varan using binary rewriting.  This overhead is negligible for
\lighttpd, \memcached and most \redis operations, \nginxIntercept for \nginx,
and \beanstalkdIntercept for \beanstalkd.

For all benchmarks, we see that the performance overhead increases
slightly with the number of followers.  For instance, the overhead for
\beanstalkd increases from \beanstalkdOneFollower for one follower to
\beanstalkdSixFollowers for six followers, while the overhead for
\lighttpd increases from \lighttpdOneFollower to
\lighttpdSixFollowers.

The figure also shows that there is a significant difference across
benchmarks: the worst performer is \beanstalkd, which sees performance
degradations in the range of \SIrange{55}{81}{\percent}, while the best performers are
\lighttpd, with only \SIrange{12}{15}{\percent} overhead and some operations in \redis
(not shown separately in Figure~\ref{fig:servers})
%such as \lstinline`LRANGE_300`, \lstinline`LRANGE_500` and \lstinline`LRANGE_600`
with under \SI{3}{\percent} overhead.

