\subsection{Comparison with prior NVX systems}
\label{sec:comparison}

While Sections~\ref{sec:microbenchmarks} and \ref{sec:c10k} illustrate
some of the worst-case synthetic and real-world scenarios for a system
call monitor, in order to compare \varan directly with prior NVX
systems, we have also run it on the same set of benchmarks used to
evaluate prior systems.  In particular, we chose to compare against two
state-of-the-art NVX systems---\orchestra~\cite{orchestra09} and
\tachyon~\cite{tachyon12}---as well as \mx. These systems and their
benchmarks are briefly described  in the first three columns of
Table~\ref{tbl:systems}. To our knowledge, we are the first to perform
an extensive performance comparison of existing NVX systems.

To allow for more faithful comparison, the benchmarks were run on a pair of
machines, one running the server under \varan and the other the client, as this
was the setup used by both \orchestra and \tachyon as well as \mx. The machines
were located in the same rack, connected by a 1 Gb Ethernet link.

\begin{table}[t]
\begin{center}
\caption{Comparison with \mx, \orchestra and \tachyon on the benchmarks used to evaluate these systems.}
\label{tbl:systems}
\begin{tabular}{lllrr}
  \toprule
  \textsc{System} & \textsc{Mechanism} & \textsc{Benchmarks} & \textsc{Overhead} & \textsc{\varan} \\

  \midrule
  \mx                 & \ptrace & \lighttpd (\httpload) & \mxLighttpd & \lighttpdHttploadOneFollower \\
                      &  & \redis (\redisbenchmark) & \mxRedis & \redisOneFollower \\
                      &  & \speczerosix & \mxSpec & \speczerosixOneFollower \\
  %\hline
  %\strata~\cite{cox2006} & modified kernel & \httpd (WebBench 5.0) & \strataHttpd & \httpdWebBenchOneFollower  \\
  \hline
  \orchestra~\cite{orchestra09} & \ptrace & \httpd (\apachebench)    & \orchestraHttpd & \httpdAbOneFollower  \\
                                &        & \speczerozero & \orchestraSpec & \speczerozeroOneFollower \\
  \hline
  \tachyon~\cite{tachyon12} & \ptrace & \lighttpd (\apachebench) & \tachyonLighttpd & \lighttpdAbOneFollower \\
                            & & \thttpd (\apachebench) & \tachyonThttpd & \thttpdOneFollower \\
  \bottomrule
\end{tabular}
\end{center}
\end{table}

\begin{figure}[!t]
 \centering
 \includegraphics[width=\textwidth]{efficient-execution/graphs/comparison}
 \caption{Performance overhead for the \httpd, \thttpd, and \lighttpd
   servers for different numbers of followers to allow for comparison
   with existing systems.}
 \label{fig:comparison}
\end{figure}


The last two columns of Table~\ref{tbl:systems} show the cumulative
results.  Since prior systems only handle two versions, the comparison
is done against \varan configured in the same way.  However, we remind
the reader that one of the strengths of \varan's decentralised
architecture is that it can often handle multiple versions with small
additional overhead, and below we also show how \varan performs on
these benchmarks when more than two versions are used.

\begin{enumerate}

\item[\httpd\footnote{\url{https://httpd.apache.org/}}]
was used by \orchestra.  We used version 1.3.29, the same as in the original
work~\cite{orchestra09}.  The overhead reported for \orchestra is
\orchestraHttpd using the \apachebench benchmark. \varan introduces
\httpdAbOneFollower overhead using the same benchmark, which is a significant
improvement.  Figure~\ref{fig:comparison} shows the overhead introduced by
\varan for \httpd (and the other servers used to evaluate prior work) with
different numbers of followers.  As it can be seen, \varan scales very well
with increasing numbers of followers for these benchmarks.

%was used by both \strata and \orchestra.  We used version 1.3.29
%mentioned by \orchestra (\strata did not report the version used).
%The overhead reported for \orchestra is \orchestraHttpd using the
%\emph{ApacheBench} benchmark and \strataHttpd for \strata using
%\emph{WebBench 5.0}. \varan introduces \httpdWebBenchOneFollower overhead
%using \emph{WebBench} and \httpdAbOneFollower overhead with
%\emph{ApacheBench}, which is an improvement over previous work.

\item[\lighttpd\footnote{\url{http://www.lighttpd.net/}}]
has been used to evaluate both \mx (\S\ref{sec:performance}) and \tachyon.  We
used version 1.4.36 as in case of \mx (\tachyon did not report the version
used).  For \mx we used the \httpload benchmark and reported up to \mxLighttpd
overhead while \tachyon used the \apachebench benchmark and reported a up
to \tachyonLighttpd overhead.  When benchmarked using \httpload, \varan
introduced at most \lighttpdHttploadOneFollower overhead, while with
\apachebench it introduced no noticeable overhead.  This marks a
significant improvement over previous work.

\item[\thttpd\footnote{\url{http://www.acme.com/software/thttpd/}}]
was shown to introduce \tachyonThttpd overhead when run on top of
\tachyon using the \apachebench benchmark. When run on top of
\varan using the same settings as in \cite{tachyon12}, we have not
measured any noticeable overhead.

\item[\redis\footnote{\url{http://redis.io/}}]
was used in the evaluation of \mx (\S\ref{sec:performance}), in particular the
version 1.3.8. The performance overhead incurred by \mx is up to \mxRedis using
the \redisbenchmark utility. When run with \varan using the same benchmark and
the same workload, the overhead we measured was no more than \redisOneFollower.

\begin{figure}[!t]
  \centering
  \includegraphics[width=\textwidth]{efficient-execution/graphs/spec2000}
  \caption{\speczerozero performance overhead for different numbers of followers.}
  \label{fig:spec2000}
\end{figure}

\item[\speczerozero\footnote{\url{http://www.spec.org/cpu2000/}}]
was used to evaluate \orchestra.  We used the latest available version 1.3.1.
\orchestra reported a \orchestraSpec average overhead, while \varan introduced
only a \speczerozeroOneFollower average overhead. The results for the
individual applications contained in the \speczerozero suite and for different
numbers of followers can be seen in Figure~\ref{fig:spec2000}.

\begin{figure}[!t]
  \centering
  \includegraphics[width=\textwidth]{efficient-execution/graphs/spec2006}
  \caption{\speczerosix performance overhead for different numbers of followers.}
  \label{fig:spec2006}
\end{figure}

\item[\speczerosix\footnote{\url{http://www.spec.org/cpu2006/}}]
was used in the \mx evaluation (\S\ref{sec:performance}). The average overhead
of \mx is \mxSpec, while the average overhead of \varan is
\speczerosixOneFollower.  Individual results can be seen in
Figure~\ref{fig:spec2006}.

\end{enumerate}

\begin{figure}[ht]
\begin{center}
\includegraphics[angle=270,width=\textwidth]{safe-updates/graphs/syscall}
\caption{Average number of system calls per second during the execution of the
SPEC~CPU2006 benchmark suite, measured using the \strace tool.}
\label{fig:syscall}
\end{center}
\end{figure}

The reason why some of the \speccpu applications scale poorly with the number
of followers is likely due to memory pressure and caching
effects~\cite{jaleel07}, and to the fact that our machine has only four
physical cores (with two logical cores each). To get a better insight into this
issue, we have also examined how the frequency of system calls affects the
performance overhead. Figure~\ref{fig:syscall} shows the average number of
system calls during the execution of \speczerosix. As it can be observed,
\textsf{452.libquantum} has the lowest average number of system calls per
second, but the largest runtime overhead. For comparison, \textsf{400.perlbench}
has the highest average number of system calls per second, but bellow average
runtime overhead. This confirms that the increased overhead is not caused by
the system call handling mechanism and can be likely attributed to memory
effects.

%\begin{figure}[!t]
  %\centering
  %\includegraphics[width=\columnwidth]{results/macro_beanstalkd}
  %\caption{Beanstalkd performance overhead.}
  %\label{fig:macro_beanstalkd}
%\end{figure}

%\begin{figure}[!t]
  %\centering
  %\includegraphics[width=\columnwidth]{results/macro_lighttpd}
  %\caption{Lighttpd performance overhead.}

